#!/usr/bin/python
# -*- coding: utf-8 -*-
##############################################################
# Nom : Mohamed AIT MANSOUR	 / BELGHARBI Meryem				 #
# Source : M2 ILSEN - Avignon University					 #
##############################################################

# librairies import
import pandas as pd
from matplotlib import cm
import matplotlib.pyplot as plt
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.preprocessing import Imputer
import seaborn as sns
from sklearn import tree
from graphviz import render
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

def replace_missing_value(df, number_features):

    imputer = Imputer(strategy="median")
    df_num = df[number_features]
    imputer.fit(df_num)
    X = imputer.transform(df_num)
    res_def = pd.DataFrame(X, columns=df_num.columns)
    return res_def

# read input text and put data inside a data frame
data = pd.read_csv('../data/base_prospect.csv', encoding='latin-1')
data=replace_missing_value(data,["effectif","ca_total_FL","ca_export_FK","evo_risque","age","chgt_dir","rdv"])
# data head
print("\n\n\nData Head \n")
print( data .head())
X=data[["effectif","ca_total_FL","ca_export_FK","evo_risque","age","chgt_dir"]]
Y=data.rdv 
feature_names=["effectif","ca_total_FL","ca_export_FK","evo_risque","age","chgt_dir"]
# Separate the data into train and test set
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3)
#X_test.fillna(X_train.mean(), inplace=True)
# Letâ€™s build a classification tree using the age to predict Rdv  in order to discretise the age variable.
tree_model = tree.DecisionTreeClassifier(max_depth=7)

tree_model.fit(X_train, y_train)
print(X.columns)
data_feature_names=["effectif","ca_total_FL","ca_export_FK","evo_risque","age","chgt_dir"]


tree.export_graphviz(tree_model,out_file="../plot/tree_model.gv",
                                feature_names=data_feature_names,
                                filled=True,
                                rounded=True)
render('dot', 'png', "../plot/tree_model.gv") 
#X_train['Age_tree']=tree_model.predict_proba(X_train.age.to_frame())[:,1] 

# Checking the number of unique values present in Age_treevariable
#print("\n\n\nChecking the number of unique values present in Age_tree variable \n")
#print(X_train.Age_tree.unique())

#print("\n\n\nChecking the number of unique values present in Effectif_tree variable \n")

#tree_model.fit(X_train, X_train.rdv)
#X_train['Effectif_tree']=tree_model.predict_proba(X_train.effectif.to_frame())[:,1] 
#print(X_train.Effectif_tree.unique())
# [0.09929511 0.11159631 0.07396272 0.12752876]
#Why only four probabilities right?
#Above in input four, we have mentioned max_depth = 2. A tree of depth 2, makes 2 splits, therefore generating 4 buckets, that is why we see 4 different probabilities in the output above.

# Check the relationship between the discretized variable Age_tree and the target Rdv.
#fig = plt.figure()
##fig = X_train.groupby(['Age_tree'])['rdv'].mean().plot()
##fig.set_title('Monotonic relationship between discretised Age and target')
##fig.set_ylabel('Rdv')
##plt.savefig('../plot/relationship_between-age_and_rdv.png')
##
### Check the relationship between the discretized variable Age_tree and the target Rdv.
##
##fig = X_train.groupby(['Effectif_tree'])['rdv'].mean().plot()
##fig.set_title('Monotonic relationship between discretised effectif and target')
##fig.set_ylabel('Rdv')
#plt.savefig('../plot/relationship_between-effectif_and_rdv.png')

# Checking Age limit buckets generated by the tree
#age_limit=pd.concat( [X_train.groupby(['Age_tree'])['age'].min(),
#            X_train.groupby(['Age_tree'])['age'].max()], axis=1)
#print("\n\nChecking Age limit buckets generated by the tree")
#print(age_limit)#

## Checking Effectif limit buckets generated by the tree
#effectif_limit=pd.concat( [X_train.groupby(['Effectif_tree'])['effectif'].min(),
#            X_train.groupby(['Effectif_tree'])['effectif'].max()], axis=1)
#print("\n\nChecking effectif limit buckets generated by the tree")
#print(effectif_limit)
##          age  age
#Age_tree          
#0.070112   51  118
#0.098843   15   50
#0.109923    8   14
#0.124174    1    7

# Visualizing the tree.
tree.export_graphviz(tree_model,out_file="../plot/tree_model.gv") 
render('dot', 'png', "../plot/tree_model.gv")  
#
#
## Selecting the optimal depth of the tree
#del X_train["rdv"]
#score_ls = []     # here I will store the roc auc
#score_std_ls = [] # here I will store the standard deviation of the roc_auc
#for tree_depth in [1,2,3,4,5,6,7,8,9,10]:
#    tree_model = tree.DecisionTreeClassifier(max_depth=tree_depth)
#    
#    scores = cross_val_score(tree_model, X_train,       
#    y_train, cv=3, scoring='roc_auc')   
#    
#    score_ls.append(np.mean(scores))
#    
#    score_std_ls.append(np.std(scores))
#    
#temp = pd.concat([pd.Series([1,2,3,4,5,6,7,8,9,10]), pd.Series(score_ls), pd.Series(score_std_ls)], axis=1)
#
#temp.columns = ['depth', 'roc_auc_mean', 'roc_auc_std']
#print(temp)
#   depth  roc_auc_mean  roc_auc_std
#0      1      0.517246     0.003489
#1      2      0.522004     0.002799 BEST ONE (min)
#2      3      0.524326     0.004934
#3      4      0.522983     0.004450
#4      5      0.521127     0.004865
#5      6      0.519065     0.006803
#6      7      0.520258     0.007909
#7      8      0.517861     0.004806
#8      9      0.517344     0.004874
#9     10      0.517841     0.006280


#Transform the Age variable using tree
#print("\n\nTransform the Age variable using tree")
#
#tree_model = tree.DecisionTreeClassifier(max_depth=2)
#tree_model.fit(X_train.age.to_frame(), X_train.rdv)
#X_train['Age_tree'] = tree_model.predict_proba(X_train.age.to_frame())[:,1]
#X_test['Age_tree'] = tree_model.predict_proba(X_test.age.to_frame())[:,1]
#
## Inspecting the transformed age variable in the train set
#print("\n\nInspecting the transformed age variable in the train set")
#print(X_train.head())
#
## Checking the unique values of each bin in the train set
#print("\n\nChecking the unique values of each bin in the train set")
#print(X_train.Age_tree.unique())
#
#
##  Inspecting the transformed age variable in the test set
#print("\n\nInspecting the transformed age variable in the test set")
#print(X_test.head())
#
##Checking the unique values of each bin in the train set
#print("\n\nChecking the unique values of each bin in the train set")
#print(X_test.Age_tree.unique())#